{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d55f6284",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spectral_entropy\n",
    "import re\n",
    "\n",
    "# Load the peak table from an Excel file\n",
    "peak_table = pd.read_excel(\"WW.xlsx\")\n",
    "\n",
    "# Remove trailing ':' from the 'MSMS spectrum' column\n",
    "peak_table['MSMS spectrum'] = peak_table['MSMS spectrum'].str.rstrip(':')\n",
    "\n",
    "# MN2.0 parameters\n",
    "similarity_threshold = 0.5\n",
    "PMD_table_path = \"PMD.xlsx\"\n",
    "PMD_table = pd.read_excel(PMD_table_path)\n",
    "\n",
    "ms2_threshold = 0.1  # m/z tolerance (Da).\n",
    "\n",
    "# Function to process the MS/MS spectrum and return a dictionary\n",
    "def process_spectrum(spectrum):\n",
    "    if isinstance(spectrum, float):\n",
    "        return {}\n",
    "    return dict((float(mz.split(':')[0]), float(mz.split(':')[1])) for mz in spectrum.split(' '))\n",
    "\n",
    "# Apply the function to create 'MSMS_dict'\n",
    "peak_table['MSMS_dict'] = peak_table['MSMS spectrum'].apply(process_spectrum)\n",
    "\n",
    "# Calculate neutral loss and store in 'NL_spectrum'\n",
    "peak_table['NL_spectrum'] = peak_table.apply(lambda row: {round(row['Precursor m/z'] - mz, 5): intensity for mz, intensity in row['MSMS_dict'].items() if row['Precursor m/z'] - mz > 0}, axis=1)\n",
    "\n",
    "# Convert the 'NL_spectrum' into a string format\n",
    "peak_table['NL_spectrum_str'] = peak_table['NL_spectrum'].apply(lambda x: ' '.join([f'{mz}:{intensity}' for mz, intensity in x.items()]))\n",
    "\n",
    "# Create a new DataFrame to store processed data\n",
    "nodetable1 = pd.DataFrame(columns=[\"precursor\", \"RT\", \"PeakID\", \"ms2_data\", \"NL_data\"])\n",
    "\n",
    "# Iterate over the rows in the peak table\n",
    "for index, row in peak_table.iterrows():\n",
    "    # If 'MSMS spectrum' is not empty\n",
    "    if not pd.isna(row[\"MSMS spectrum\"]):\n",
    "        precursor = row[\"Precursor m/z\"]\n",
    "        ms2_data = row[\"MSMS spectrum\"]\n",
    "        PeakID = row[\"PeakID\"]\n",
    "        \n",
    "        # Convert MS/MS spectrum data to DataFrame\n",
    "        ms2_df = pd.DataFrame([entry.split(':') for entry in ms2_data.split(\" \")], columns=[\"mz\", \"intensity\"])\n",
    "        ms2_df[\"mz\"] = ms2_df[\"mz\"].astype(float)\n",
    "        ms2_df[\"intensity\"] = ms2_df[\"intensity\"].astype(float)\n",
    "        \n",
    "        # Clean the spectrum using spectral_entropy library\n",
    "        clean_spectrum = spectral_entropy.clean_spectrum(ms2_df.to_numpy(), max_mz=800, noise_removal=0.01, ms2_da=0.01)\n",
    "        RT = row[\"RT (min)\"]\n",
    "        \n",
    "        # Process neutral loss spectrum\n",
    "        NL_data = row[\"NL_spectrum_str\"]\n",
    "        NL_df = pd.DataFrame([entry.split(':') for entry in NL_data.split()], columns=[\"mz\", \"intensity\"])\n",
    "        NL_df[\"mz\"] = NL_df[\"mz\"].astype(float)\n",
    "        NL_df[\"intensity\"] = NL_df[\"intensity\"].astype(float)\n",
    "        \n",
    "        clean_NL_spectrum = spectral_entropy.clean_spectrum(NL_df.to_numpy(), max_mz=precursor, noise_removal=0.01, ms2_da=0.01)\n",
    "        \n",
    "        # Append to nodetable1 DataFrame\n",
    "        nodetable1 = nodetable1.append({\"precursor\": precursor, \"RT\": RT, \"PeakID\": PeakID, \"ms2_data\": clean_spectrum, \"NL_data\": clean_NL_spectrum}, ignore_index=True)\n",
    "    \n",
    "    # If 'MSMS spectrum' is empty\n",
    "    if pd.isna(row[\"MSMS spectrum\"]):\n",
    "        precursor = row[\"Precursor m/z\"]\n",
    "        RT = row[\"RT (min)\"]\n",
    "        PeakID = row[\"PeakID\"]\n",
    "        nodetable1 = nodetable1.append({\"precursor\": precursor, \"RT\": RT, \"PeakID\": PeakID}, ignore_index=True)\n",
    "\n",
    "# Remove rows with missing 'ms2_data'\n",
    "nodetable1 = nodetable1.dropna(subset=['ms2_data'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2148a2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create an empty DataFrame to store similarity scores\n",
    "similarity_df = pd.DataFrame(columns=[\"Precursor_a\", \"PeakID_a\", \"Precursor_b\", \"PeakID_b\", \"Mass_difference\"])\n",
    "similarity_df1 = []\n",
    "similarity_df2 = []\n",
    "\n",
    "# Iterate through all possible combinations to calculate similarity\n",
    "max_index = max(nodetable1.index)\n",
    "\n",
    "# Only loop through the first two rows with other rows\n",
    "for index_a, row_a in nodetable1.iterrows():\n",
    "    if index_a >= 2:  # Only process the first two rows\n",
    "        break\n",
    "\n",
    "    for index_b in range(index_a + 1, max_index + 1):\n",
    "        if index_b in nodetable1.index:\n",
    "            row_b = nodetable1.loc[index_b]\n",
    "            Precursor_a = row_a[\"precursor\"]\n",
    "            Precursor_b = row_b[\"precursor\"]\n",
    "            Mass_difference = Precursor_b - Precursor_a\n",
    "            PeakID_a = row_a[\"PeakID\"]\n",
    "            ms2_data_a = row_a[\"ms2_data\"]\n",
    "            NL_data_a = row_a[\"NL_data\"]\n",
    "            PeakID_b = row_b[\"PeakID\"]\n",
    "            ms2_data_b = row_b[\"ms2_data\"]\n",
    "            NL_data_b = row_b[\"NL_data\"]\n",
    "\n",
    "            # Convert MS2 data to DataFrame\n",
    "            ms2_df_a = pd.DataFrame(ms2_data_a, columns=[\"mz\", \"intensity\"])\n",
    "            NL_df_a = pd.DataFrame(NL_data_a, columns=[\"mz\", \"intensity\"])\n",
    "            ms2_df_b = pd.DataFrame(ms2_data_b, columns=[\"mz\", \"intensity\"])\n",
    "            NL_df_b = pd.DataFrame(NL_data_b, columns=[\"mz\", \"intensity\"])\n",
    "\n",
    "            # Ensure data types are float\n",
    "            for df in [ms2_df_a, NL_df_a, ms2_df_b, NL_df_b]:\n",
    "                df[\"mz\"] = df[\"mz\"].astype(float)\n",
    "                df[\"intensity\"] = df[\"intensity\"].astype(float)\n",
    "\n",
    "            # Calculate similarity\n",
    "            all_dist = spectral_entropy.all_similarity(ms2_df_a.to_numpy(), ms2_df_b.to_numpy(), ms2_da=0.05)\n",
    "            similarity_values1 = {spectral_entropy.methods_name[dist_name]: value for dist_name, value in all_dist.items()}\n",
    "            similarity_df1.append(similarity_values1)\n",
    "\n",
    "            all_dist = spectral_entropy.all_similarity(NL_df_a.to_numpy(), NL_df_b.to_numpy(), ms2_da=0.005)\n",
    "            similarity_values2 = {spectral_entropy.methods_name[dist_name] + \"_NL\": value for dist_name, value in all_dist.items()}\n",
    "            similarity_df2.append(similarity_values2)\n",
    "\n",
    "            # Add similarity scores to DataFrame\n",
    "            similarity_df = similarity_df.append({\n",
    "                \"Precursor_a\": Precursor_a,\n",
    "                \"PeakID_a\": PeakID_a,\n",
    "                \"Precursor_b\": Precursor_b,\n",
    "                \"PeakID_b\": PeakID_b,\n",
    "                \"Mass_difference\": Mass_difference\n",
    "            }, ignore_index=True)\n",
    "\n",
    "# Convert similarity score lists to DataFrames\n",
    "similarity_df1 = pd.DataFrame(similarity_df1)\n",
    "similarity_df2 = pd.DataFrame(similarity_df2)\n",
    "\n",
    "# Merge results\n",
    "result_df = pd.concat([similarity_df, similarity_df1, similarity_df2], axis=1)\n",
    "\n",
    "# Remove rows where PeakID_a and PeakID_b are equal\n",
    "result_df = result_df[result_df['PeakID_a'] != result_df['PeakID_b']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40ab46aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2.0: Further processing and assigning molecular formulas\n",
    "\n",
    "# Keep the first 5 columns\n",
    "columns_to_keep = result_df.columns[:5].tolist()\n",
    "\n",
    "# Check for additional columns and add them to the list\n",
    "additional_columns = ['MSforID distance version 1', 'MSforID distance version 1_NL']\n",
    "for col in additional_columns:\n",
    "    if col in result_df.columns:\n",
    "        columns_to_keep.append(col)\n",
    "    else:\n",
    "        raise KeyError(f\"Column {col} not found in the DataFrame.\")\n",
    "\n",
    "# Retain only the required columns\n",
    "result_df = result_df[columns_to_keep]\n",
    "result_df = result_df[result_df['MSforID distance version 1'] > similarity_threshold]\n",
    "\n",
    "# Add 'Reaction' and 'Description' columns to result_df\n",
    "result_df['Reaction'] = None\n",
    "result_df['Description'] = None\n",
    "\n",
    "# Iterate through the 'Mass_difference' column in result_df\n",
    "for idx, mass_diff in result_df['Mass_difference'].iteritems():\n",
    "    # Find matching rows in PMD_table\n",
    "    matches = PMD_table[abs(PMD_table['Mass Difference (Da)'] - abs(mass_diff)) <= ms2_threshold]\n",
    "    \n",
    "    # If matching rows are found, assign 'Reaction' and 'Description' to result_df\n",
    "    if not matches.empty:\n",
    "        result_df.at[idx, 'Reaction'] = matches['Reaction'].values[0]\n",
    "        result_df.at[idx, 'Description'] = matches['Description'].values[0]\n",
    "\n",
    "# Create a new column to ensure consistent order of inchikey1 and inchikey2\n",
    "result_df['sorted_inchikeys'] = result_df.apply(lambda row: tuple(sorted([row['PeakID_a'], row['PeakID_b']])), axis=1)\n",
    "\n",
    "# Retain the rows with the maximum similarity for the same sorted_inchikeys\n",
    "result_df_max_similarity = result_df.loc[\n",
    "    result_df.groupby(['sorted_inchikeys'])['MSforID distance version 1'].idxmax()\n",
    "].reset_index(drop=True)\n",
    "\n",
    "# Drop the temporary column\n",
    "result_df = result_df_max_similarity.drop(columns=['sorted_inchikeys'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7cec22fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_excel(\"WWsimilarity-PMD.xlsx\", index=False, encoding='utf-8-sig')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311-scz",
   "language": "python",
   "name": "py311-scz"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
